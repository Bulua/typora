[toc]

#### 1、问题定义

假设我们有两张图片，我们想要比较图片中内容是否相似，以一个相似度来判断两张图像的相似度。本文采用比较两张图片的色相`（Hue，H）`、饱和度`（Saturation，S）`、亮度`（Value，V）`和图像轮廓综合计算出一个相似度得分，进而比较是否相似。

#### 2、算法流程

1. 使用流行的`opencv`库读取图片$img_1, img_2$。
2. `opencv`默认读取图片的通道是`B、G、R`，因此需要将其转换为`H、S、V`通道。
3. 根据`V`通道的信息计算图像边缘特征$edges$。
4. 计算$img_1$和$img_2$图像的`H、S、V、edges`之间的距离，距离函数采用像素差均值来计算，得到$diss$，包含`4`个距离值。
5. 另外可以给四个距离设置相应的权重$weights$，默认四个$weight$大小都为`1.0`。
6. 根据$weight$和$diss$求和，再求平均，得到差异值$diff_{score}$。
7. 设定阈值$th=27.0$，比较$diff_{score}$与$th$的大小，大于$th$时，则图片之间差异过大，否则差异性可以接受。

#### 3、环境准备

```txt
opencv, numpy
```

#### 4、完整代码

```python
import cv2
import math
import numpy as np

def estimated_kernel_size(frame_width: int, frame_height: int) -> int:
    size: int = 4 + round(math.sqrt(frame_width * frame_height) / 192)
    if size % 2 == 0:
        size += 1
    return size

def detect_edges(lum: np.ndarray, _kernel: None) -> np.ndarray:
    if _kernel is None:
        kernel_size = estimated_kernel_size(lum.shape[1], lum.shape[0])
        _kernel = np.ones((kernel_size, kernel_size), np.uint8)

    sigma: float = 1.0 / 3.0
    median = np.median(lum)
    low = int(max(0, (1.0 - sigma) * median))
    high = int(min(255, (1.0 + sigma) * median))

    edges = cv2.Canny(lum, low, high)
    return cv2.dilate(edges, _kernel)

def mean_pixel_distance(left: np.ndarray, right: np.ndarray) -> float:
    assert len(left.shape) == 2 and len(right.shape) == 2, 'The length of the two images shape should be consistent'
    assert left.shape == right.shape, 'The shape of the two images should be consistent'
    num_pixels: float = float(left.shape[0] * left.shape[1])
    return (np.sum(np.abs(left.astype(np.int32) - right.astype(np.int32))) / num_pixels)

def read_img_feature(img: np.ndarray) -> tuple():
    hue, sat, lum = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))
    edges = detect_edges(lum, None)
    return hue, sat, lum, edges

def calculate_img_diff_score(img1: np.ndarray, img2: np.ndarray, weights: np.ndarray) -> tuple():
    if weights is None:
        delta_hue: float = 1.0
        delta_sat: float = 1.0
        delta_lum: float = 1.0
        delta_edges: float = 1.0
        weights = np.array([delta_hue, delta_sat, delta_lum, delta_edges])
    
    fs1 = read_img_feature(img1)
    fs2 = read_img_feature(img2)
    
    diss = np.zeros(4)
    for n, (i, j) in enumerate(zip(fs1, fs2)):
        diss[n] = mean_pixel_distance(i, j)
    return (diss @ weights) / np.sum(np.abs(weights))
```

`calculate_img_diff_score`函数接收三个参数，

- `img1`：必须为`numpy.ndarray`类型，且为`BGR`通道格式。

- `img1`：必须为`numpy.ndarray`类型，且为`BGR`通道格式。

  $img_1$**和**$img_2$**像素的宽和高必须相等**。

- `weights`：四个权重参数，分别为`H、S、V、edges`的权重。

#### 5、举例

假设我们输入一段视频，需要将存在镜头切换的场景找出来，我们计算相邻帧之间的差异性，差异过大则存在镜头切换场景。

下面给出调用示例：

```python
video_path = 'input.mp4'
cap = cv2.VideoCapture(video_path)
last_frame = None
threshold = 27.0
idx = 1

while True:
    ret, frame = cap.read()
    if not ret:
        break
    if last_frame is None:
        last_frame = frame
        continue
    diff_score = calculate_img_diff_score(last_frame, frame, None)
    if diff_score > threshold:
        print(f'There is a significant difference between frame {idx-1} and frame {idx}!')
    last_frame = frame
    idx += 1
# There is a significant difference between frame 241 and frame 242!
# There is a significant difference between frame 337 and frame 338!
# There is a significant difference between frame 555 and frame 556!
```

**程序仅输出发生切换的帧的位置，如果需要对视频裁剪，请做额外的处理，下面是我做额外处理后的结果：**

|                           原视频：                           |
| :----------------------------------------------------------: |
| ![h1mqb-54w6y](https://raw.githubusercontent.com/Bulua/BlogImageBed/master/h1mqb-54w6y.gif)<br/> |



|                          切分效果：                          |
| :----------------------------------------------------------: |
| ![rbg4d-8grk2](https://raw.githubusercontent.com/Bulua/BlogImageBed/master/rbg4d-8grk2.gif)<br/>![oxc2l-icm05](https://raw.githubusercontent.com/Bulua/BlogImageBed/master/oxc2l-icm05.gif)<br/>![s5zxo-32tiw](https://raw.githubusercontent.com/Bulua/BlogImageBed/master/s5zxo-32tiw.gif)<br/>![88v42-u7jjn](https://raw.githubusercontent.com/Bulua/BlogImageBed/master/88v42-u7jjn.gif)<br/> |

