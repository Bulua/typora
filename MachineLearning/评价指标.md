[toc]



# 1、混淆矩阵

## 1.1 变量介绍

混淆矩阵（Confusion Matrix）是在分类问题中用于评估模型性能的一种表格。它显示了模型的预测结果与实际标签之间的关系，特别是在多类别分类问题中。

对于一个二分类问题，混淆矩阵通常如下所示：

|                   | Actual Class 0 | Actual Class 1 |
| :---------------: | :------------: | :------------: |
| Predicted Class 0 |       TP       |       FP       |
| Predicted Class 1 |       FN       |       TN       |

*初学者容易搞混TP、FP、FN、TN，这里教大家一个方法来记住他们到底怎么来的：第二个字母是你预测的 P 还是 N ，第一个字母是你预测的对不对，对的话就是 T ，不对的话是 N*

在混淆矩阵中：

- True Positive (TP)：模型正确预测为正类别的样本数。
- True Negative (TN)：模型正确预测为负类别的样本数。
- False Positive (FP)：模型错误地将负类别预测为正类别的样本数（误报）。
- False Negative (FN)：模型错误地将正类别预测为负类别的样本数（漏报）。

## 1.2 Accuracy

准确率（Accuracy）是分类问题中常用的性能度量之一，它表示模型==正确预测的样本数==占==总样本数==的比例。准确率可以用以下公式表示：
$$
Accuracy = \frac{TP+TF}{TP+TF+NP+NF}
$$

## 1.3 Precision

Precision（精确率，又称查准率）是分类问题中的一种性能度量，它表示模型在预测为正类别的样本中有多少是真正的正类别。Precision 可以用以下公式表示：
$$
Precision = \frac{TP}{TP+FP}
$$

## 1.4 Recall

Recall（召回率，又称查全率）是分类问题中的一种性能度量，它表示模型在所有真正的正类别中有多少被成功地检测到。Recall 可以用以下公式表示：
$$
Recall = \frac{TP}{TP+FN}
$$
*Precision和Recall是一对矛盾的指标。一般来说，Precision高时，Recall往往偏低；二Recall高时，Precision往往偏低。*

## 1.5 F1-score

F1-score（F1分数）是综合考虑 Precision 和 Recall 的一种性能度量，特别适用于不平衡类别的情况。F1-score 可以通过以下公式计算：
$$
\begin{aligned}
\text{F1-score} &= \frac{2}{\frac{1}{Precision}+\frac{1}{Recall}}	\\
&= \frac{2 \times Precision \times Recall}{Precision+Recall}
\end{aligned}
$$
