[toc]

# é«˜æ–¯æ··åˆæ¨¡å‹

é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆ`GMM`ï¼‰çš„å·¥ä½œåŸç†å’Œ `KMeans` éå¸¸ç›¸ä¼¼ï¼Œç”šè‡³å¯ä»¥è®¤ä¸ºå®ƒæ˜¯ `KMeans` çš„æ¦‚ç‡ç‰ˆæœ¬ã€‚ **ä»æ¦‚å¿µä¸Šè§£é‡Šï¼šé«˜æ–¯æ··åˆæ¨¡å‹å°±æ˜¯ç”¨é«˜æ–¯æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆæ­£æ€åˆ†å¸ƒæ›²çº¿ï¼‰ç²¾ç¡®åœ°é‡åŒ–äº‹ç‰©ï¼Œå®ƒæ˜¯ä¸€ä¸ªå°†äº‹ç‰©åˆ†è§£ä¸ºè‹¥å¹²çš„åŸºäºé«˜æ–¯æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆæ­£æ€åˆ†å¸ƒæ›²çº¿ï¼‰å½¢æˆçš„æ¨¡å‹ã€‚**

## 1ã€GMMçš„å·¥ä½œåŸç†

æ­£å¦‚å‰é¢æåˆ°çš„ï¼Œå¯ä»¥å°† `GMM` ç§°ä¸º æ¦‚ç‡çš„`KMeans`ï¼Œè¿™æ˜¯å› ä¸º `KMeans `å’Œ `GMM `çš„èµ·ç‚¹å’Œè®­ç»ƒè¿‡ç¨‹æ˜¯ç›¸åŒçš„ã€‚ ä½†æ˜¯ï¼Œ`KMeans `ä½¿ç”¨åŸºäºè·ç¦»çš„æ–¹æ³•ï¼Œè€Œ `GMM `ä½¿ç”¨æ¦‚ç‡æ–¹æ³•ã€‚ `GMM `ä¸­æœ‰ä¸€ä¸ªä¸»è¦å‡è®¾ï¼šæ•°æ®é›†ç”±å¤šä¸ªé«˜æ–¯åˆ†å¸ƒç»„æˆï¼Œæ¢å¥è¯è¯´ï¼Œ`GMM `æ¨¡å‹å¯ä»¥çœ‹ä½œæ˜¯ç”± `K `ä¸ªå•é«˜æ–¯æ¨¡å‹ç»„åˆè€Œæˆçš„æ¨¡å‹,è¿™` K `ä¸ªå­æ¨¡å‹æ˜¯æ··åˆæ¨¡å‹çš„éšå˜é‡`(Hidden variable)`ã€‚

<img src="./imgs/image-20230919153904059.png" alt="image-20230919153904059" style="zoom: 80%;" />

ä¸Šè¿°åˆ†å¸ƒé€šå¸¸ç§°ä¸ºå¤šæ¨¡å‹åˆ†å¸ƒã€‚ æ¯ä¸ªå³°ä»£è¡¨æˆ‘ä»¬æ•°æ®é›†ä¸­ä¸åŒçš„é«˜æ–¯åˆ†å¸ƒæˆ–èšç±»ã€‚ æˆ‘ä»¬è‚‰çœ¼å¯ä»¥çœ‹åˆ°è¿™äº›åˆ†å¸ƒï¼Œä½†æ˜¯ä½¿ç”¨å…¬å¼å¦‚ä½•ä¼°è®¡è¿™äº›åˆ†å¸ƒå‘¢ï¼Ÿ

åœ¨è§£é‡Šè¿™ä¸ªé—®é¢˜ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆåˆ›å»ºä¸€äº›é«˜æ–¯åˆ†å¸ƒã€‚è¿™é‡Œæˆ‘ä»¬ç”Ÿæˆçš„æ˜¯å¤šå…ƒæ­£æ€åˆ†å¸ƒï¼› å®ƒæ˜¯å•å˜é‡æ­£æ€åˆ†å¸ƒçš„æ›´é«˜ç»´æ‰©å±•ã€‚

é¦–å…ˆï¼Œå¯¼å…¥éœ€è¦çš„å·¥å…·åŒ…ï¼š

```python
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from scipy.stats import multivariate_normal
from scipy.stats import norm
import warnings
import random
```

è®©æˆ‘ä»¬å®šä¹‰æ•°æ®ç‚¹çš„å‡å€¼å’Œåæ–¹å·®ã€‚ ä½¿ç”¨å‡å€¼å’Œåæ–¹å·®ï¼Œæˆ‘ä»¬å¯ä»¥ç”Ÿæˆå¦‚ä¸‹åˆ†å¸ƒã€‚

```python
# Generate some data with multiple modes
data1 = np.random.normal(0, 1, 1000)
data2 = np.random.normal(5, 1, 1000)

# Plot the data using seaborn's distplot function
sns.distplot(data1, kde=True, hist=True, bins=100, color='b', hist_kws={'alpha': 0.5})
sns.distplot(data2, kde=True, hist=True, bins=100, color='r', hist_kws={'alpha': 0.5})

# Add a legend
plt.legend(['Data 1', 'Data 2'])

# Show the plot
plt.show()
```

å¯è§†åŒ–ä¸€ä¸‹ç”Ÿæˆçš„æ•°æ®

```python
plt.figure(figsize=(10,6))

plt.scatter(data1[:,0],data1[:,1])
plt.scatter(data2[:,0],data2[:,1])

sns.kdeplot(x=data1[:, 0], y=data1[:, 1], levels=20, linewidth=10, color='k', alpha=0.2)
sns.kdeplot(x=data2[:, 0], y=data2[:, 1], levels=20, linewidth=10, color='k', alpha=0.2)

plt.grid(True)
plt.show()
```

<img src="./imgs/image-20230919154323680.png" alt="image-20230919154323680" style="zoom:80%;" />

æˆ‘ä»¬ä¸Šé¢æ‰€åšçš„å·¥ä½œæ˜¯ï¼šä½¿ç”¨å‡å€¼å’Œåæ–¹å·®çŸ©é˜µç”Ÿæˆäº†éšæœºé«˜æ–¯åˆ†å¸ƒã€‚ è€Œ `GMM `è¦åšæ­£å¥½ä¸è¿™ä¸ªç›¸åï¼Œä¹Ÿå°±æ˜¯æ‰¾åˆ°ä¸€ä¸ªåˆ†å¸ƒçš„**å‡å€¼**å’Œ**åæ–¹å·®**ï¼Œé‚£ä¹ˆæ€ä¹ˆåšå‘¢ï¼Ÿ

å·¥ä½œè¿‡ç¨‹å¤§è‡´å¦‚ä¸‹ï¼š

ä¸ºç»™å®šçš„æ•°æ®é›†ç¡®å®šèšç±»çš„æ•°é‡ï¼ˆè¿™é‡Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢†åŸŸçŸ¥è¯†æˆ–å…¶ä»–æ–¹æ³•ï¼Œä¾‹å¦‚ `BIC/AIC`ï¼‰ã€‚ æ ¹æ®æˆ‘ä»¬ä¸Šé¢çš„å‚æ•°ï¼Œæœ‰ 1000 ä¸ªæ•°æ®ç‚¹ï¼Œå’Œä¸¤ä¸ªç°‡2ã€‚

åˆå§‹åŒ–æ¯ä¸ªç°‡çš„**å‡å€¼ã€åæ–¹å·®**å’Œ**æƒé‡å‚æ•°**ã€‚

ä½¿ç”¨==æœŸæœ›æœ€å¤§åŒ–ç®—æ³•==æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

- æœŸæœ›æ­¥éª¤ï¼ˆ`E-step`ï¼‰ï¼šè®¡ç®—æ¯ä¸ªæ•°æ®ç‚¹å±äºæ¯ä¸ªåˆ†å¸ƒçš„æ¦‚ç‡ï¼Œç„¶åä½¿ç”¨å‚æ•°çš„å½“å‰ä¼°è®¡è¯„ä¼°ä¼¼ç„¶å‡½æ•°
- æœ€å¤§åŒ–æ­¥éª¤ï¼ˆ`M-step`ï¼‰ï¼šæ›´æ–°ä¹‹å‰çš„å‡å€¼ã€åæ–¹å·®å’Œæƒé‡å‚æ•°ï¼Œè¿™æ ·æœ€å¤§åŒ–Eæ­¥éª¤ä¸­æ‰¾åˆ°çš„é¢„æœŸä¼¼ç„¶
- é‡å¤è¿™äº›æ­¥éª¤ï¼Œç›´åˆ°æ¨¡å‹æ”¶æ•›ã€‚

ä»¥ä¸Šæ˜¯`GMM `ç®—æ³•çš„éæ•°å­¦çš„é€šä¿—åŒ–çš„è§£é‡Šã€‚

## 2ã€GMMæ•°å­¦åŸç†

ä¸Šé¢çš„è§£é‡Šå¯ä»¥çœ‹åˆ°`GMM `çš„æ ¸å¿ƒåœ¨äºä¸Šä¸€èŠ‚ä¸­æè¿°çš„æœŸæœ›æœ€å¤§åŒ– (EM) ç®—æ³•ã€‚åœ¨è§£é‡Šä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¼”ç¤ºä¸€ä¸‹ `EM `ç®—æ³•åœ¨ `GMM` ä¸­çš„åº”ç”¨ã€‚

åœ¨è§£é‡Šä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¼”ç¤ºä¸€ä¸‹ `EM `ç®—æ³•åœ¨ `GMM `ä¸­çš„åº”ç”¨ã€‚

### 2.1 åˆå§‹åŒ–

- `mean (Î¼)`ï¼šéšæœºåˆå§‹åŒ–
- åæ–¹å·® ($\sigma$)ï¼šéšæœºåˆå§‹åŒ–
- æƒé‡ï¼ˆæ··åˆç³»æ•°ï¼‰($\pi$)ï¼šæ¯ä¸ªç±»çš„åˆ†æ•°æ˜¯æŒ‡ç‰¹å®šæ•°æ®ç‚¹å±äºæ¯ä¸ªç±»çš„å¯èƒ½æ€§ã€‚ ä¸€å¼€å§‹ï¼Œè¿™å¯¹æ‰€æœ‰ç°‡éƒ½æ˜¯å¹³ç­‰çš„ã€‚ å‡è®¾æˆ‘ä»¬ç”¨ä¸‰ä¸ªåˆ†é‡æ‹Ÿåˆ `GMM`ï¼Œé‚£ä¹ˆæ¯ä¸ªç»„ä»¶çš„æƒé‡å‚æ•°å¯èƒ½è®¾ç½®ä¸º `1/3`ï¼Œè¿™æ ·æ¦‚ç‡åˆ†å¸ƒä¸º `(1/3, 1/3, 1/3)`ã€‚

### 2.2 æœŸæœ›æ­¥éª¤(E-step)

å¯¹äºæ¯ä¸ªæ•°æ®ç‚¹$x_i$ï¼Œä½¿ç”¨ä»¥ä¸‹ç­‰å¼è®¡ç®—æ•°æ®ç‚¹å±äºç°‡ (`ğ‘`) çš„æ¦‚ç‡ã€‚ è¿™é‡Œçš„`k`æ˜¯åˆ†å¸ƒï¼ˆç°‡ï¼‰æ•°ã€‚
$$
r_{ic} = \frac{\pi_cN(x_i|Î¼_c, \sigma_c)}{\sum_{k=1}^{K} \ \pi_k N(x_i|Î¼_k,\sigma_k)}
$$
ä¸Šé¢çš„$ğœ‹_ğ‘$æ˜¯é«˜æ–¯åˆ†å¸ƒ`c`çš„æ··åˆç³»æ•°ï¼ˆæœ‰æ—¶ç§°ä¸ºæƒé‡ï¼‰ï¼Œå®ƒåœ¨ä¸Šä¸€é˜¶æ®µè¢«åˆå§‹åŒ–ï¼Œ$N(x|Î¼, \sigma)$æè¿°äº†é«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆ`PDF`ï¼‰ï¼Œå‡å€¼ä¸º`ğœ‡`å’Œ å…³äºæ•°æ®ç‚¹ `x `çš„åæ–¹å·® $\sigma$ï¼› æ‰€ä»¥å¯ä»¥æœ‰å¦‚ä¸‹è¡¨ç¤ºã€‚
$$
N(x_i|Î¼_c, \sigma_c) \ = \ \frac{1}{(2\pi)^\frac{n}{2}|\sigma_c|^\frac{1}{2}} \ exp(-\frac{(x_i-Î¼_c)^T \ \sigma_c^{-1}(x_i-Î¼_c)}{2})
$$
`E-step` ä½¿ç”¨æ¨¡å‹å‚æ•°çš„å½“å‰ä¼°è®¡å€¼è®¡ç®—æ¦‚ç‡ã€‚ è¿™äº›æ¦‚ç‡é€šå¸¸ç§°ä¸ºé«˜æ–¯åˆ†å¸ƒçš„â€œ`responsibilities`â€ã€‚ å®ƒä»¬ç”±å˜é‡$ r_{i,c} $è¡¨ç¤ºï¼Œå…¶ä¸­` i `æ˜¯æ•°æ®ç‚¹çš„ç´¢å¼•ï¼Œ`c` æ˜¯é«˜æ–¯åˆ†å¸ƒçš„ç´¢å¼•ã€‚ `responsibilities`è¡¡é‡ç¬¬ `c `ä¸ªé«˜æ–¯åˆ†å¸ƒå¯¹ç”Ÿæˆç¬¬ `i `ä¸ªæ•°æ®ç‚¹â€œè´Ÿè´£â€çš„ç¨‹åº¦ã€‚ è¿™é‡Œä½¿ç”¨æ¡ä»¶æ¦‚ç‡ï¼Œæ›´å…·ä½“åœ°è¯´æ˜¯è´å¶æ–¯å®šç†ã€‚

ä¸€ä¸ªç®€å•çš„ä¾‹å­ã€‚ å‡è®¾æˆ‘ä»¬æœ‰ `100 `ä¸ªæ•°æ®ç‚¹ï¼Œéœ€è¦å°†å®ƒä»¬èšç±»æˆä¸¤ç»„ã€‚ æˆ‘ä»¬å¯ä»¥è¿™æ ·å†™ $r_{i,c}(i=20,c=1) $ã€‚ å…¶ä¸­ `i `ä»£è¡¨æ•°æ®ç‚¹çš„ç´¢å¼•ï¼Œ`c` ä»£è¡¨æˆ‘ä»¬æ­£åœ¨è€ƒè™‘çš„ç°‡çš„ç´¢å¼•ã€‚

ä¸è¦å¿˜è®°åœ¨å¼€å§‹æ—¶ï¼Œ$ğœ‹_ğ‘ $ä¼šåˆå§‹åŒ–ä¸ºç­‰å€¼ã€‚ åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œ$ğœ‹_1 = ğœ‹_2 = 1/2$ã€‚
$$
r_{20,1} \ = \ \frac{\pi_1 \ N(x_{20}|Î¼_1, \sigma_1)}{\pi_1 \ N(x_{20}|Î¼_1, \sigma_1) + \pi_2N(x_20|Î¼_2,\sigma_2)}
$$
`E-step` çš„ç»“æœæ˜¯æ··åˆæ¨¡å‹ä¸­æ¯ä¸ªæ•°æ®ç‚¹å’Œæ¯ä¸ªé«˜æ–¯åˆ†å¸ƒçš„ä¸€ç»„`responsibilities`ã€‚ è¿™äº›`responsibilities`ä¼šåœ¨` M-step`æ›´æ–°æ¨¡å‹å‚æ•°çš„ä¼°è®¡ã€‚

### 2.3 æœ€å¤§åŒ–æ­¥éª¤(M-step)

ç®—æ³•ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒçš„`responsibilities`ï¼ˆåœ¨ `E-step`ä¸­è®¡ç®—çš„ï¼‰æ¥æ›´æ–°æ¨¡å‹å‚æ•°çš„ä¼°è®¡å€¼ã€‚

`M-step`æ›´æ–°å‚æ•°çš„ä¼°è®¡å¦‚ä¸‹ï¼š
$$
\pi_c = \frac{\sum_{i=1}^m \ r_{i,c}}{m} \\
Î¼_c = \frac{\sum_{i=1}^m \ r_{i,c} x_i}{\sum_{i=1}^m \ r_{i,c}} \\
\sigma_c = \frac{\sum_{i=1}^m \ r_{i,c}(x_i-Î¼_c)^2}{\sum_{i=1}^m \ r_{i,c}}
$$
æ›´æ–°åçš„çš„ä¼°è®¡ä¼šåœ¨ä¸‹ä¸€ä¸ª` E-step `ä¸­ç”¨äºè®¡ç®—æ•°æ®ç‚¹çš„æ–°`responsibilities`ã€‚

`GMM `å°†å°†é‡å¤è¿™ä¸ªè¿‡ç¨‹ç›´åˆ°ç®—æ³•æ”¶æ•›ï¼Œé€šå¸¸åœ¨æ¨¡å‹å‚æ•°ä»ä¸€æ¬¡è¿­ä»£åˆ°ä¸‹ä¸€æ¬¡è¿­ä»£æ²¡æœ‰æ˜¾ç€å˜åŒ–æ—¶å°±è¢«è®¤ä¸ºæ”¶æ•›äº†ã€‚

## 3ã€Pythonå®ç°GMM

### 3.1 æ•°æ®ç”Ÿæˆ

```python
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn import mixture

mean1 = [4, 3]
mean2 = [2, 5]
cov1 = [[1, .7], [.7, 1]]
cov2 = [[.5, .4], [.4, .5]]

data1 = np.random.multivariate_normal(mean1, cov1, size=1000)
data2 = np.random.multivariate_normal(mean2, cov2, size=1000)

plt.figure(figsize=(8,5))

plt.scatter(data1[:,0],data1[:,1])
plt.scatter(data2[:,0],data2[:,1])

sns.kdeplot(x=data1[:, 0], y=data1[:, 1], levels=20, linewidth=10, color='k', alpha=0.2)
sns.kdeplot(x=data2[:, 0], y=data2[:, 1], levels=20, linewidth=10, color='k', alpha=0.2)

plt.grid(False)
plt.show()
```

<img src="./imgs/image-20230919160837017.png" alt="image-20230919160837017" style="zoom:80%;" />

### 3.2 è®­ç»ƒé¢„æµ‹

```python
def GMM(dataMat, components=3, iter=100, cov_type="full"):
    clst = mixture.GaussianMixture(n_components=components, max_iter=iter, covariance_type=cov_type)
    clst.fit(dataMat)
    predicted_labels = clst.predict(dataMat)
    return clst.means_, predicted_labels     # clst.means_è¿”å›å‡å€¼

data_mat = np.concatenate([data1, data2])
means, pred = GMM(data_mat, components=2)

# è¾“å‡º
means: array([[3.98718668, 3.01706299],
      		  [2.00677432, 5.02003172]])
pred: array([0, 0, 0, ..., 1, 1, 1])
```



























