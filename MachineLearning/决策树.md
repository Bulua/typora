[toc]



#### 信息增益

**熵**表示随机变量不确定性，随机变量的取值等概率分布时，相应的**熵**最大。假设有`K`个类，样本点属于第`k`个类的概率为$p_k$，**熵**的表达式：
$$
\text{H}(X) = \text{H}(p) = - \sum_{k=1}^K \ p_k \ log \ p_k
$$
条件**熵**：
$$
\text{H}(Y|X) = - \sum_{i=1}^n \ p_i \ H(Y|X=x_i)
$$
信息增益（`Gain`）：
$$
\text{Gain}(D, A) = \text{H}(D) -\text{H}(D|A)
$$
其中$\text{H}(D)$可以理解为不知道**特征**$A$的情况下依据`label`计算得出的熵，而$A$表示特征信息。

信息增益比：
$$
GR(D,A) = \frac{Gain(D,A)}{H(D)}
$$


#### 基尼指数

基尼指数（`Gini`），假设有`K`个类，样本点属于第`k`个类的概率为$p_k$，则概率分布的基尼指数为：
$$
\text{Gini}(p) = \sum_{k=1}^Kp_k(1-p_k) = 1-\sum_{k=1}^K p_k^2
$$
以二分类为例，二分类的基尼指数为：
$$
\text{Gini}(p) = p(1-p)+(1-p)p = 2p(1-p)
$$
样本集$D$的基尼指数为：
$$
\text{Gini}(D) = 1 - \sum_{k=1}^K(\frac{|C_k|}{D})^2
$$
特征$A$条件下，样本集$D$的基尼指数为：
$$
\text{Gini}(D, A) = \frac{|D_1|}{|D|}Gini(D_1) + \frac{|D_2|}{|D|}Gini(D_2)
$$
