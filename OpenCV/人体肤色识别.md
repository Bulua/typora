[toc]

#### 1、简介

在第一阶段，使用平均滤波器对输入图像帧进行平滑处理，以减少光照条件差的非线性影响。然后，将经过平滑处理的`RGB`图像帧转换为`YCbCr`颜色空间。这里选择`YCbCr`颜色空间，因为它将亮度分量和色度分量明显分开，色度分量大多不受光照变化的影响。在第二阶段，对`YCbCr`图像帧的三个分量分别采用`Otsu`的灰度阈值方法进行肤色区域的检测。它类似于无监督视频阈值方法，除了三个主要区别。首先，该方法采用`YCbCr`颜色空间，而在无监督视频中采用`RGB`颜色空间。第二个区别是，非监督方法为每个像素分配3位码字，具有相同码字的像素被聚类。然后，比较类间和类内的方差来估计肤色区域。但是，该方法通过使用布尔和运算结合单个阈值二值图像帧来简单地估计肤色区域。第三个区别是，输入图像帧在应用于灰度阈值之前是平滑的，而无监督方法不涉及平滑过程。

#### 2、预处理

在实践中，皮肤颜色的强度与非皮肤颜色有很大的不同，而且它更有可能只在亮度成分方面发生变化`RGB`颜色空间主要依赖于光照条件，对亮度差比较敏感。`RGB`颜色空间由于其通道之间的高度相关性以及色度和亮度数据的混合，不适合用于颜色分析另一方面，`YCrCb`颜色空间既有亮度分量(Y)，也有蓝(Cb)和红(Cr)色度分量。

在`YCbCr`颜色空间中，亮度分量(Y)与色度分量明显分离，色度平面上肤色聚类紧凑，减少了搜索空间在不同光照条件下，`YCbCr`颜色空间中皮肤数据与非皮肤数据的重叠很小。

因此，该方法使用YCbCr颜色空间进行肤色建模。首先，利用平均平滑滤波器对输入图像帧进行平滑处理，以提高全局阈值处理的性能。设r、g、b为RGB颜色分量。然后将平滑后的输入图像帧由RGB转换为Y、Cb、Cr分量，转换过程如下:
$$
\begin{aligned}
Y &= 0.299r + 0.587g + 0.114b \\
Cr &= r - y	\\
Cb &= b - y
\end{aligned}
$$

#### 3、皮肤检测

预处理步骤完成后，利用`Otsu`的全局阈值法检测肤色区域`Otsu`的方法基于给定图像帧中目标分割的最优全局阈值对皮肤区域进行聚类假设每一输入图像帧包含`N`个像素，每个像素用`L`个灰度级表示`(1, 2, ..., L)`。设`t`是将图像帧像素分为两种不同类别的最佳阈值，即前景(即灰度级别为1至`t`的像素)和背景(即灰度级别为`t` 从 `1`到`L`的像素)。`Otsu`的方法评估对应于类内方差最小或类间方差最大的最佳阈值。类内方差$var_a^2(t)$的计算方法如下:
$$
var_a^2(t) = p_1(t)var_1^2(t)+p_2(t)var_2^2(t)	\tag{2}
$$
其中$p_i(t)$和$var_i^2(t)$是两个类(前景类和背景类)的类概率和类方差。假设$(p_i)_1^L$是图像直方图，由图像直方图确定类概率$p_1(t)$和$p_2(t)$如下:
$$
p_1(t) = \sum_{i=1}^{i=t}p_i	\tag{3}
$$

$$
p_2(t) = \sum_{i=t+1}^{i=L}p_i	\tag{4}
$$

在方程式`(3) (4)`中， $p_i$表示图像帧中出现第`i`个灰度级的概率。对于给定的图像帧，通过全阈值范围`(1 ~ L)`计算类内方差，选择最小的类内方差对应的阈值$var_a^2(t)$作为最优阈值。这种`Otsu`阈值计算方法是计算密集型的。并且，最小化类内方差等于最大化类间方差，且类间方差的计算要比类内方差快。因此，本方法通过估计类间方差来进行最优阈值计算。

类间方差$var_b^2(t)$表示为:
$$
var_b^2(t) = var^2-var_a^2(t) = p_1(t)p_2(t)[m_1(t)-m_2(t)]^2	\tag{5}
$$
其中，$var^2$和$var_a^2(t)$是总方差和类内方差。$m_1(t)$和$m_2(t)$是类均值，计算方式如下:
$$
m_1(t) = \frac{\sum_{k=1}^{k=t}p_k · k}{p_1(t)}	\tag{6}
$$

$$
m_2(t) = \frac{\sum_{k=t+1}^{k=L}p_k · k}{p_2(t)}	\tag{7}
$$

对所有可能的阈值`(1 ~ L)`进行类间方差计算，得到最大类间方差$var_b^2(t)$所对应的最优阈值如下:
$$
t = arg \ max\{var_b^2(t)\}_1^L	\tag{8}
$$
设$t_Y、t_{Cb}、t_{Cr}$分别为`YCbCr`组分的阈值。设视频图像中的每个像素表示为$p_{x,y} = (Y_{x,y}, Cb_{x,y}, Cr_{x,y})$，其中$(x,y)$是空间坐标。然后，对每个颜色域进行如下阈值化处理:
$$
Y_{x,y} = 1; if \ \ Y_{x,y} > t_Y \ \ else \ \ 0;	\\
Cb_{x,y} = 1; if \ \ Cb_{x,y} < t_{Cb} \ \ else \ \ 0;	\\
Cr_{x,y} = 1; if \ \ Cr_{x,y} > t_{Cr} \ \ else \ \ 0;	\\
(经过测试，Cr_{x,y}的结果是论文中写错了)\\ \tag{9}
$$

#### 4、测试结果

为了效果更好，不受背景影响，左边图片是我使用`Yolov8-seg`切出来的。<img src="https://raw.githubusercontent.com/Bulua/BlogImageBed/master/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20231027115328.png" alt="微信截图_20231027115328" style="zoom:67%;" />
<img src="https://raw.githubusercontent.com/Bulua/BlogImageBed/master/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20231027115258.png" alt="微信截图_20231027115258" style="zoom: 55%;" />
<img src="https://raw.githubusercontent.com/Bulua/BlogImageBed/master/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20231027115100.png" alt="微信截图_20231027115100" style="zoom:67%;" />

#### 5、代码

```python
def otsu(img):
    '''
    img: BGR
    '''
    img_ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(img_ycrcb)
    
    t_y,  image_y  = cv2.threshold(y, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    t_cr, image_cr = cv2.threshold(cr, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    t_cb, image_cb = cv2.threshold(cb, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    mask_y  = np.where(image_y > t_y, 1, 0)[:, :, None]
    mask_cr = np.where(image_cr > t_cr, 1, 0)[:, :, None]
    mask_cb = np.where(image_cb < t_cb, 1, 0)[:, :, None]
    
    skin_mask = np.all(np.concatenate([mask_y, mask_cr, mask_cb], axis=-1), axis=-1)
    return skin_mask
```

#### 参考文献

[1]Kaliraj K ,Manimaran S . Robust skin color-based moving object detection for video surveillance[J]. Journal of Electronic Imaging,2016,25(4).